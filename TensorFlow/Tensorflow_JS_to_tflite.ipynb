{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[TensorFlow Lite Converter] Tensorflow JS to tflite.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1T5a997NZj28L_Avyjlfh9WG98cxID0cr",
      "authorship_tag": "ABX9TyPlo9zQHI4z+yWVy+qSrt6H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weilly0912/Core-ML/blob/main/TensorFlow/Tensorflow_JS_to_tflite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcMUgv1GEqkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d21c21-ef05-47a1-cea6-f2ceaabd02ce"
      },
      "source": [
        "!pip install tfjs-graph-converter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully installed tensorflowjs-3.7.0 tfjs-graph-converter-1.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCtpWh4UOD0v"
      },
      "source": [
        "# **PoseNet : JS to TFLite (mobilenet/float/050)**\n",
        "\n",
        "https://stackoverflow.com/questions/62544836/how-to-convert-from-tensorflow-js-json-model-into-tensorflow-savedmodel-or"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odTgH3iK8wvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fdfeefa-5874-49a1-dde6-7b69223fa3b3"
      },
      "source": [
        "%cd /root/\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/posenet/mobilenet/float/050/model-stride16.json\n",
        "!wget https://www.gstaticcnapps.cn/tfjs-models/savedmodel/posenet/mobilenet/float/050/group1-shard1of1.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "--2021-06-23 04:27:17--  https://storage.googleapis.com/tfjs-models/savedmodel/posenet/mobilenet/float/050/model-stride16.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.26.128, 172.217.193.128, 172.217.204.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.26.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/json]\n",
            "Saving to: ‘model-stride16.json’\n",
            "\n",
            "model-stride16.json     [ <=>                ]  48.53K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-06-23 04:27:17 (55.8 MB/s) - ‘model-stride16.json’ saved [49696]\n",
            "\n",
            "--2021-06-23 04:27:17--  https://www.gstaticcnapps.cn/tfjs-models/savedmodel/posenet/mobilenet/float/050/group1-shard1of1.bin\n",
            "Resolving www.gstaticcnapps.cn (www.gstaticcnapps.cn)... 74.125.141.94, 2607:f8b0:400c:c06::5e\n",
            "Connecting to www.gstaticcnapps.cn (www.gstaticcnapps.cn)|74.125.141.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2309836 (2.2M) [text/html]\n",
            "Saving to: ‘group1-shard1of1.bin’\n",
            "\n",
            "group1-shard1of1.bi 100%[===================>]   2.20M  8.79MB/s    in 0.3s    \n",
            "\n",
            "2021-06-23 04:27:18 (8.79 MB/s) - ‘group1-shard1of1.bin’ saved [2309836/2309836]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD1PiS9ZEq5Z"
      },
      "source": [
        "import tfjs_graph_converter.api as tfjs\n",
        "tfjs.graph_model_to_saved_model(\"/root/model-stride16.json\",\"realsavedmodel\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfixZm5QJxUM"
      },
      "source": [
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"realsavedmodel\")\n",
        "tflite_model = converter.convert()\n",
        "# Save the TF Lite model.\n",
        "with tf.io.gfile.GFile('/root/posenet.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5AaSQGzQH9V"
      },
      "source": [
        "#TFLite\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "def representative_dataset_gen():\n",
        "    for _ in range(250):\n",
        "        yield [np.random.uniform(0.0, 1.0, size=(1, 192, 192, 3)).astype(np.float32)] #需要輸入端大小\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"realsavedmodel\")\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type  = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "tflite_model = converter.convert()\n",
        "with open('/root/_simplepose_sp-mobilenetv2_uint8.tflite','wb') as f:\n",
        "  f.write(tflite_model)\n",
        "print(\"tranfer done!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skmv8gnXZrH3"
      },
      "source": [
        "# **PoseNet : JS to TFLite (mobilenet/quant/075)**\n",
        "https://tfhub.dev/tensorflow/tfjs-model/posenet/mobilenet/float/075/1/default/1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBhedI7kOUZN"
      },
      "source": [
        "#!link google driver\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd /root\n",
        "!tar zxvf /content/gdrive/MyDrive/\"Colab DataSet\"/\"Pose Moel\"/posenet_mobilenet_float_075_1_default_1.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ivRmEXkeYfE"
      },
      "source": [
        "%cd /root\n",
        "!rm -r pose\n",
        "\n",
        "%cd\n",
        "!mkdir pose\n",
        "\n",
        "%cd pose\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/posenet/mobilenet/quant1/075/model-stride8.json\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/posenet/mobilenet/quant1/075/model-stride16.json\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/posenet/mobilenet/quant1/075/group1-shard1of1.bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B-fKtxSaDpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb64cad-4c67-425b-cabc-69ad50fd7d9b"
      },
      "source": [
        "import tfjs_graph_converter.api as tfjs\n",
        "tfjs.graph_model_to_saved_model(\"/root/pose/model-stride16.json\",\"realsavedmodel\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: realsavedmodel/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'realsavedmodel/saved_model.pb'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFvqhCS2ue01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8517daa3-2971-4f7a-a767-32aa8f0bf77c"
      },
      "source": [
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/root/pose/realsavedmodel\")\n",
        "tflite_model = converter.convert()\n",
        "# Save the TF Lite model.\n",
        "with tf.io.gfile.GFile('/root/posenet_json.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "print(\"done!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "done!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMeGE7ZQwt-q"
      },
      "source": [
        "**Meta**\n",
        "https://www.tensorflow.org/lite/convert/metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J23pzSu4uvKc"
      },
      "source": [
        "!cp /content/gdrive/MyDrive/\"Colab DataSet\"/mobilenet_v1_0.75_160_quantized_1_metadata_1.tflite /root\n",
        "!pip install tflite-support\n",
        "# 應該與 Meta 元數據無關\n",
        "populator = _metadata.MetadataPopulator.with_model_file(\"/root/posenet_mobilenet_float_075_1_metadata_1.tflite\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4aNm4Mn8cLi"
      },
      "source": [
        "# **PoseNet : JS to TFLite Application**\n",
        "輸入尺寸不同可動態調整"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcAdLL3w8Qah"
      },
      "source": [
        "# 支持 輸入端是可變尺寸\n",
        "import numpy as np\n",
        "img = tf.keras.preprocessing.image.load_img(\"/pose_test_image.jpg\")\n",
        "x = tf.keras.preprocessing.image.img_to_array(img, dtype=np.float32)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "content_image = x\n",
        "content_image.shape\n",
        "\n",
        "import tfjs_graph_converter.api as tfjs\n",
        "import tfjs_graph_converter.util as tfjs_util\n",
        "graph = tfjs.load_graph_model(\"/root/pose/model-stride16.json\")\n",
        "model_inputs = tfjs_util.get_input_nodes(graph)\n",
        "\n",
        "import tensorflow as tf\n",
        "with tf.compat.v1.Session(graph=graph) as sess:\n",
        "    # the module provides some helpers for querying model properties\n",
        "    input_tensor_names = tfjs_util.get_input_tensors(graph)\n",
        "    output_tensor_names = tfjs_util.get_output_tensors(graph)\n",
        "    input_tensor = graph.get_tensor_by_name(input_tensor_names[0])\n",
        "    results = sess.run(output_tensor_names, feed_dict={input_tensor: content_image})\n",
        "\n",
        "    #save \n",
        "    builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(\"/root/pose/realsavedmodel_size\")\n",
        "    builder.add_meta_graph_and_variables(sess, ['tag_string'])\n",
        "    builder.save()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaVM-1-X8yME"
      },
      "source": [
        "# Install Tensorflow Lite Runtime\n",
        "!pip install --extra-index-url https://google-coral.github.io/py-repo/ tflite_runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKukZkMh8zVk"
      },
      "source": [
        "# 不支持 輸入端是可變尺寸\n",
        "interpreter=tf.lite.Interpreter(\"/root/posenet_text.tflite\")\n",
        "interpreter.allocate_tensors() \n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "input_data = content_image\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhNllWLIITpX"
      },
      "source": [
        "# 動態調整 (work!!)\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(\"/pose_test_image.jpg\")\n",
        "input_data = tf.keras.preprocessing.image.img_to_array(img, dtype=np.float32)\n",
        "input_data = np.expand_dims(input_data, axis=0)\n",
        "\n",
        "interpreter=tf.lite.Interpreter(\"/root/posenet_text.tflite\")\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], (1, 705, 527, 3)) # content_image.shape = 1, 705, 527, 3\n",
        "interpreter.allocate_tensors()\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data) \n",
        "interpreter.invoke()\n",
        "heat_maps   = interpreter.get_tensor(output_details[0]['index'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zso5_rFqjXix"
      },
      "source": [
        "# **BodyFix : JS to TFLite (mobilenet/float/075)**\n",
        "Error -> nnrt::layout_inference::IPermuteVectorPtr): Assertion `false' failed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1dxB9_3jTwA"
      },
      "source": [
        "%cd /root\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/mobilenet/quant1/075/model-stride16.json\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/mobilenet/quant1/075/group1-shard1of1.bin\n",
        "\n",
        "!rm -r /root/realsavedmodel\n",
        "\n",
        "import tfjs_graph_converter.api as tfjs\n",
        "tfjs.graph_model_to_saved_model(\"/root/model-stride16.json\",\"realsavedmodel\")\n",
        "\n",
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/root/realsavedmodel\")\n",
        "tflite_model = converter.convert()\n",
        "# Save the TF Lite model.\n",
        "with tf.io.gfile.GFile('/root/bodypix_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "print(\"done!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFZ1qH4IjufJ"
      },
      "source": [
        "'''\n",
        "Loaded model bodypix_model.tflite\n",
        "resolved reporter\n",
        "INFO: Created TensorFlow Lite delegate for NNAPI.\n",
        "Applied NNAPI delegate.label_image: ./op/operation.cpp:5[  262.816437] audit: type=1701 audit(1622886583.853:4): auid=4294967295 uid=0 gid=0 ses=4294967295 pid=1164 comm=\"label_image\" exe=\"/home/root/.cache/eiq/eIQSwitchLabelImage/bin/label_image\" sig=6 res=1\n",
        "45: void nnrt::op::Operation::permuteConstOperands(nnrt::Model&, std::vector<unsigned int>&, nnrt::layout_inference::IPermuteVectorPtr): Assertion `false' failed.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm5lDTBLmSvE"
      },
      "source": [
        "# **BodyFix : JS to TFLite (mobilenet/quant/050)** \n",
        "Error -> nnrt::layout_inference::IPermuteVectorPtr): Assertion `false' failed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwhD6GaumNLa"
      },
      "source": [
        "%cd /root/\n",
        "!rm -r bodypix\n",
        "!mkdir bodypix\n",
        "%cd bodypix\n",
        "\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/mobilenet/quant2/075/model-stride16.json\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/mobilenet/quant2/075/group1-shard1of1.bin\n",
        "\n",
        "import tfjs_graph_converter.api as tfjs\n",
        "tfjs.graph_model_to_saved_model(\"/root/bodypix/model-stride16.json\",\"realsavedmodel\")\n",
        "\n",
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/root/bodypix/realsavedmodel\")\n",
        "tflite_model = converter.convert()\n",
        "# Save the TF Lite model.\n",
        "with tf.io.gfile.GFile('/root/bodypix_mobilenet_q2_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "print(\"done!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-675HNTdlN6F"
      },
      "source": [
        "# **BodyFix : JS to TFLite (resnet50/quant/050)**\n",
        "Work ->  91MB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5aSpvRRlO1b"
      },
      "source": [
        "%cd /root/\n",
        "!rm -r bodypix\n",
        "!mkdir bodypix\n",
        "%cd bodypix\n",
        "\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/resnet50/quant1/model-stride16.json\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/resnet50/quant1/group1-shard1of6.bin\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/resnet50/quant1/group1-shard2of6.bin\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/resnet50/quant1/group1-shard3of6.bin\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/resnet50/quant1/group1-shard4of6.bin\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/resnet50/quant1/group1-shard5of6.bin\n",
        "!wget https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/resnet50/quant1/group1-shard6of6.bin\n",
        "\n",
        "import tfjs_graph_converter.api as tfjs\n",
        "tfjs.graph_model_to_saved_model(\"/root/bodypix/model-stride16.json\",\"realsavedmodel\")\n",
        "\n",
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/root/bodypix/realsavedmodel\")\n",
        "tflite_model = converter.convert()\n",
        "# Save the TF Lite model.\n",
        "with tf.io.gfile.GFile('/root/bodypix_resnet50_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "print(\"done!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl4adgIIOWeY"
      },
      "source": [
        "# **BodyFix : JS to TFLite (TF Hub)** \n",
        "Error - > ModelFormatError: unsupported model format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6J39xMZOVOQ"
      },
      "source": [
        "%cd /root/\n",
        "!rm -r bodypix\n",
        "!mkdir bodypix\n",
        "%cd bodypix\n",
        "\n",
        "# Download Json and Weight(bin)\n",
        "!tar zxvf /content/gdrive/MyDrive/\"Colab DataSet\"/\"Google Application\"/bodypix_075_1_default_1.tar.gz\n",
        "\n",
        "# Converter Pb\n",
        "import tfjs_graph_converter.api as tfjs\n",
        "tfjs.graph_model_to_saved_model(\"/root/bodypix/model.json\",\"realsavedmodel\")\n",
        "\n",
        "# Converter TF Lite\n",
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/root/bodypix/realsavedmodel\")\n",
        "tflite_model = converter.convert()\n",
        "# Save the TF Lite model.\n",
        "with tf.io.gfile.GFile('/root/bodypix.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "print(\"done!!\")\n",
        "\n",
        "#Error\n",
        "'''\n",
        "ModelFormatError: unsupported model format: ''\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvmI9-HSKZxS"
      },
      "source": [
        "# **Facemesh : JS to TFLite (TF Hub)** \n",
        "Error -> INFO:tensorflow:Saver not created because there are no variables in the graph to restore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poQ7KixAKWW7"
      },
      "source": [
        "%cd /root/\n",
        "!mkdir facemesh\n",
        "%cd facemesh\n",
        "\n",
        "# Download Json and Weight(bin)\n",
        "!tar zxvf /content/gdrive/MyDrive/\"Colab DataSet\"/\"Google Application\"/facemesh_1_default_1.tar.gz\n",
        "\n",
        "# Converter Pb\n",
        "import tfjs_graph_converter.api as tfjs\n",
        "tfjs.graph_model_to_saved_model(\"/root/facemesh/model.json\",\"realsavedmodel\")\n",
        "\n",
        "# Converter TF Lite\n",
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/root/facemesh/realsavedmodel\")\n",
        "tflite_model = converter.convert()\n",
        "# Save the TF Lite model.\n",
        "with tf.io.gfile.GFile('/root/facemesh_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "print(\"done!!\")\n",
        "\n",
        "#Error\n",
        "'''\n",
        "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGxhb40sVqqL"
      },
      "source": [
        "# **FacelandMark : JSON To TF Lite (Github)** \n",
        "source : https://github.com/610265158/face_landmark\n",
        "\n",
        "Error -> ERROR: Didn't find op for builtin opcode 'TRANSPOSE' version '4'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hby2bj8MZ2A"
      },
      "source": [
        "%cd /root/\n",
        "!rm -r facelandmark\n",
        "!mkdir facelandmark\n",
        "%cd facelandmark\n",
        "\n",
        "#!link google driver\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Download Json and Weight(bin)\n",
        "!unzip /content/gdrive/MyDrive/\"Colab DataSet\"/\"Google Application\"/keypoints-20210607T025953Z-001.zip\n",
        "\n",
        "# Converter TF Lite\n",
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/root/facelandmark/keypoints\")\n",
        "tflite_model = converter.convert()\n",
        "# Save the TF Lite model.\n",
        "with tf.io.gfile.GFile('/root/facelandmark_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "print(\"done!!\")\n",
        "\n",
        "\n",
        "#Error\n",
        "'''\n",
        "ERROR: Didn't find op for builtin opcode 'TRANSPOSE' version '4'\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOq068HBestb"
      },
      "source": [
        "# **Handskeleton : JSON To TF Lite (TF Hub)** \n",
        "Error -> failed while converting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb6U4Cxtb-kr"
      },
      "source": [
        "%cd /root/\n",
        "!rm -r handskeleton\n",
        "!mkdir handskeleton\n",
        "%cd handskeleton\n",
        "\n",
        "# Download Json and Weight(bin)\n",
        "!tar zxvf /content/gdrive/MyDrive/\"Colab DataSet\"/\"Google Application\"/handskeleton_1_default_1.tar.gz\n",
        "\n",
        "# Converter Pb\n",
        "import tfjs_graph_converter.api as tfjs\n",
        "tfjs.graph_model_to_saved_model(\"/root/handskeleton/model.json\",\"realsavedmodel\")\n",
        "\n",
        "# Converter TF Lite\n",
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/root/handskeleton/realsavedmodel\")\n",
        "tflite_model = converter.convert()\n",
        "# Save the TF Lite model.\n",
        "with tf.io.gfile.GFile('/root/handskeleton_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "print(\"done!!\")\n",
        "\n",
        "#Error\n",
        "'''\n",
        "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEAaG7mRfAwq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}